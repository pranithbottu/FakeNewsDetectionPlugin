{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CheckThat 2022 Baseline\n",
    "\n",
    "*** Author: Mina SchÃ¼tz ***\n",
    "*** E-Mail: mina.schuetz@h-da.de (1) mina.schuetz@ait.ac.at (2) ***\n",
    "*** Affiliation: Darmstadt University for Applied Sciences (1) and Austrian Institute of Technology GmbH (2) ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "# from transformers import *\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    '''\n",
    "        Params:\n",
    "        --file_path (Str) = Path to TSV/CSV file\n",
    "        Retunrs:\n",
    "        --df (DataFrame) = dataframe with containing the testdataset\n",
    "    '''\n",
    "\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\", encoding=\"utf-8\", index_col=[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    '''\n",
    "        This function changes the classes into numerical values and deletes all NullValues found in the text content\n",
    "        Params:\n",
    "         --df (DataFrame) = DataFrame containing the testset\n",
    "        Returns:\n",
    "        --df (DataFrame) = Cleaned DataFrame, prepared for preprocessing\n",
    "    \n",
    "    '''\n",
    "\n",
    "    df[\"our rating\"] = np.where(df[\"our rating\"] == \"partially false\", 2, df[\"our rating\"])\n",
    "    df[\"our rating\"] = np.where(df[\"our rating\"] == \"false\", 1, df[\"our rating\"])\n",
    "    df[\"our rating\"] = np.where(df[\"our rating\"] == \"true\", 0, df[\"our rating\"])\n",
    "    df[\"our rating\"] = np.where(df[\"our rating\"] == \"other\", 3, df[\"our rating\"])\n",
    "    df['text'].replace('', np.nan, inplace=True)\n",
    "    df['title'].replace('', np.nan, inplace=True)\n",
    "    df.dropna(subset=['title'], inplace=True)\n",
    "    df.dropna(subset=['text'], inplace=True)\n",
    "    df.dropna(subset = [\"our rating\"], inplace=True)\n",
    "    df['text'] = df['title'] +' '+ df['text']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "\n",
    "    '''\n",
    "        Params:\n",
    "        -- model_path = Path to local trained model\n",
    "        Returns:\n",
    "        -- model = BERT-model for testing\n",
    "        -- tokenizer = original BERT tokenizer from HuggingFace\n",
    "    \n",
    "    '''\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-cased', lower_case=False)\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        model_path, \n",
    "        num_labels = 4,\n",
    "        output_attentions = False, \n",
    "        output_hidden_states = False, \n",
    "    )\n",
    "\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, tokenizer):\n",
    "\n",
    "    '''\n",
    "        Preparation of a whole dataset for a forward pass through the model.\n",
    "        \n",
    "        Params:\n",
    "        -- df = Cleaned DataFrame\n",
    "        -- tokenizer = BERT Tokenizer\n",
    "        Returns:\n",
    "        -- Torch DataLoader for the Forward Pass\n",
    "    \n",
    "    '''\n",
    "\n",
    "    MAX_LEN = 512\n",
    "    batch_size = 6\n",
    "\n",
    "    test_sentences = df.text.to_list()\n",
    "    test_labels = df[\"our rating\"].to_list()\n",
    "\n",
    "    test_ids = []\n",
    "    \n",
    "    for sent in test_sentences:\n",
    "        encoded_sent = tokenizer.encode(sent, add_special_tokens = True)\n",
    "        test_ids.append(encoded_sent)\n",
    "\n",
    "    test_ids = pad_sequences(test_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
    "                          value=0, truncating=\"post\", padding=\"post\")\n",
    "    \n",
    "    test_masks = []\n",
    "    for sent in test_ids:\n",
    "        att_mask = [int(token_id > 0) for token_id in sent]\n",
    "        test_masks.append(att_mask)\n",
    "\n",
    "    test_inputs = torch.tensor(test_ids)\n",
    "    test_masks = torch.tensor(test_masks)\n",
    "    test_labels = torch.tensor(test_labels)\n",
    "\n",
    "    test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "    test_sampler = SequentialSampler(test_data)\n",
    "    test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
    "\n",
    "    return test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pass(test_dataloader, model, df):\n",
    "\n",
    "    '''\n",
    "        Evaluation of the testset.\n",
    "\n",
    "        Params: \n",
    "        -- test_dataloader = Torch DataLoader\n",
    "        -- model = The loaded model from disk\n",
    "    \n",
    "    '''\n",
    "\n",
    "    print('Prediction started')\n",
    "\n",
    "    # Set device for PyTorch\n",
    "    if torch.cuda.is_available():    \n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    # Push model to device\n",
    "    model.to(device)\n",
    "\n",
    "    # Check if GPU or CPU \n",
    "    if torch.cuda.is_available():    \n",
    "        model.cuda()\n",
    "    else:\n",
    "        print('No GPU available, using the CPU instead.')\n",
    "        model.cpu()\n",
    "    \n",
    "    # Model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Helper variables for eval metrics\n",
    "    test_accuracy, test_fone, test_precision, test_recall, nb_test_steps = 0, 0, 0, 0, 0\n",
    "    labels_arr, softmax_arr, logits_arr, argmax_arr = [], [], [], []\n",
    "\n",
    "    # Go through the batches in the Prediction Dataloader\n",
    "    for batch in test_dataloader:\n",
    "        \n",
    "        #> Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        #> Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            #> Forward pass, calculate logit predictions\n",
    "            outputs = model(b_input_ids,\n",
    "                            token_type_ids=None,\n",
    "                            attention_mask=b_input_mask)\n",
    "\n",
    "        # Detach logit outputs and labels from model\n",
    "        logits = outputs[0]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        logits_arr.append(logits)\n",
    "\n",
    "        # Softmax on logits for final class\n",
    "        logits_soft_eval = tf.nn.softmax(logits)\n",
    "        logits_arg_eval = np.argmax(logits_soft_eval, axis=1)\n",
    "        \n",
    "        # Calculate eval metrics per batch\n",
    "        tmp_test_accuracy = accuracy_score(label_ids, logits_arg_eval)\n",
    "        tmp_test_precision = precision_score(label_ids, logits_arg_eval, average=\"macro\")\n",
    "        tmp_test_recall = recall_score(label_ids, logits_arg_eval, average=\"macro\")\n",
    "        tmp_test_fone = f1_score(label_ids, logits_arg_eval, average=\"macro\")\n",
    "    \n",
    "        # Add the metrics to a global variable to calculate the actual outcome after the testing\n",
    "        test_accuracy += tmp_test_accuracy\n",
    "        test_precision += tmp_test_precision\n",
    "        test_recall += tmp_test_recall\n",
    "        test_fone += tmp_test_fone\n",
    "    \n",
    "        nb_test_steps += 1   \n",
    "        \n",
    "        # Divide the total metric with the testing steps to get the result\n",
    "        # Accuracy, Precision, Recall, and F1\n",
    "        \n",
    "    for line in logits_arr:\n",
    "        logits_soft_tmp = tf.nn.softmax(line)\n",
    "        logits_arg_tmp = np.argmax(logits_soft_tmp, axis=1)\n",
    "        softmax_arr.append(logits_soft_tmp)\n",
    "        argmax_arr.append(logits_arg_tmp)\n",
    "    \n",
    "    argmax_arr = list(chain.from_iterable(argmax_arr)) \n",
    "    \n",
    "    new_list = []\n",
    "    pred_0, pred_1, pred_2, pred_3 = [], [], [], []\n",
    "    \n",
    "    for line in softmax_arr:\n",
    "        b = line.numpy()\n",
    "        new_list.append(b)\n",
    "\n",
    "    for line in new_list:\n",
    "        for item in line:\n",
    "            pred_0.append(item[0])\n",
    "            pred_1.append(item[1])\n",
    "            pred_2.append(item[2])\n",
    "            pred_3.append(item[3])\n",
    "\n",
    "    df[\"true\"] = pred_0\n",
    "    df[\"false\"] = pred_1\n",
    "    df[\"partially false\"] = pred_2\n",
    "    df[\"other\"] = pred_3\n",
    "    df[\"final_prediction\"] = argmax_arr\n",
    "    \n",
    "    print(\" \")\n",
    "    print(\"------------------------------------------------------------------------------\")\n",
    "    print(\"------------------------------------------------------------------------------\")\n",
    "    print(\"------------------------------------------------------------------------------\")\n",
    "    print(\" \")\n",
    "    print(\"  Accuracy: {0:.2f}\".format(test_accuracy/nb_test_steps))\n",
    "    print(\" \")\n",
    "    print(\"  Precision: {0:.2f}\".format(test_precision/nb_test_steps))\n",
    "    print(\" \")\n",
    "    print(\"  Recall: {0:.2f}\".format(test_recall/nb_test_steps))\n",
    "    print(\" \")\n",
    "    print(\"  F1: {0:.2f}\".format(test_fone/nb_test_steps))\n",
    "    print(\" \")\n",
    "    print('  Testing complete.')\n",
    "    print(\" \")\n",
    "    print(\"------------------------------------------------------------------------------\")\n",
    "    print(\"------------------------------------------------------------------------------\")\n",
    "    print(\"------------------------------------------------------------------------------\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"Task3a_testing.tsv\"\n",
    "model_path = \"model_save_3/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 208k/208k [00:00<00:00, 2.94MB/s]\n",
      "Downloading: 100%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 29.0/29.0 [00:00<00:00, 14.8kB/s]\n",
      "Downloading: 100%|âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 570/570 [00:00<00:00, 190kB/s]\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction started\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.cuda.IntTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-54fe7a61781d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Test model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-a419ab5f244a>\u001b[0m in \u001b[0;36meval_pass\u001b[1;34m(test_dataloader, model, df)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[1;31m#> Forward pass, calculate logit predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             outputs = model(b_input_ids,\n\u001b[0m\u001b[0;32m     50\u001b[0m                             \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                             attention_mask=b_input_mask)\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1543\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1544\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1545\u001b[1;33m         outputs = self.bert(\n\u001b[0m\u001b[0;32m   1546\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1547\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 989\u001b[1;33m         embedding_output = self.embeddings(\n\u001b[0m\u001b[0;32m    990\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m             \u001b[0minputs_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         return F.embedding(\n\u001b[0m\u001b[0;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   1850\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1852\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.cuda.IntTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "df = load_data(file_path)\n",
    "df = prepare_data(df)\n",
    "model, tokenizer = load_model(model_path)\n",
    "test_dataloader = preprocess_data(df, tokenizer)\n",
    "\n",
    "# Test model\n",
    "df = eval_pass(test_dataloader, model, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>our rating</th>\n",
       "      <th>true</th>\n",
       "      <th>false</th>\n",
       "      <th>partially false</th>\n",
       "      <th>other</th>\n",
       "      <th>final_prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81a67c96</th>\n",
       "      <td>- The Washington Post Former state House Major...</td>\n",
       "      <td>- The Washington Post</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.997826</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6e5ec6fb</th>\n",
       "      <td>Rubio Comments on Iran Nuclear Deal Editorâs n...</td>\n",
       "      <td>Rubio Comments on Iran Nuclear Deal</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.998082</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d9cd4895</th>\n",
       "      <td>Climate Alarmists Caught Manipulating Temperat...</td>\n",
       "      <td>Climate Alarmists Caught Manipulating Temperat...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.996054</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.002919</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4a1a9b9f</th>\n",
       "      <td>Who are the arsonists setting rural fires in W...</td>\n",
       "      <td>Who are the arsonists setting rural fires in W...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.993891</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6d16fa40</th>\n",
       "      <td>Diabetes prescriptions now cost NHS Â£1bn, figu...</td>\n",
       "      <td>Diabetes prescriptions now cost NHS Â£1bn, figu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.120679</td>\n",
       "      <td>0.075827</td>\n",
       "      <td>0.740065</td>\n",
       "      <td>0.063430</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d0b0e459</th>\n",
       "      <td>Global Ocean Circulation Appears To Be Collaps...</td>\n",
       "      <td>Global Ocean Circulation Appears To Be Collaps...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.997181</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>af8069e0</th>\n",
       "      <td>Greenland's ice sheet has melted to a point of...</td>\n",
       "      <td>Greenland's ice sheet has melted to a point of...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.024827</td>\n",
       "      <td>0.012409</td>\n",
       "      <td>0.717568</td>\n",
       "      <td>0.245196</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3d1a155a</th>\n",
       "      <td>The Sea Is Rising, but Not Because of Climate ...</td>\n",
       "      <td>The Sea Is Rising, but Not Because of Climate ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003819</td>\n",
       "      <td>0.803527</td>\n",
       "      <td>0.003131</td>\n",
       "      <td>0.189523</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8060b507</th>\n",
       "      <td>Climate Change Isnât the End of the World Even...</td>\n",
       "      <td>Climate Change Isnât the End of the World</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.954236</td>\n",
       "      <td>0.026244</td>\n",
       "      <td>0.018762</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c3b3947d</th>\n",
       "      <td>Earth heading for 'mini ice age' within 15 yea...</td>\n",
       "      <td>Earth heading for 'mini ice age' within 15 years</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002841</td>\n",
       "      <td>0.909089</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.083331</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>330 rows Ã 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        text  \\\n",
       "public_id                                                      \n",
       "81a67c96   - The Washington Post Former state House Major...   \n",
       "6e5ec6fb   Rubio Comments on Iran Nuclear Deal Editorâs n...   \n",
       "d9cd4895   Climate Alarmists Caught Manipulating Temperat...   \n",
       "4a1a9b9f   Who are the arsonists setting rural fires in W...   \n",
       "6d16fa40   Diabetes prescriptions now cost NHS Â£1bn, figu...   \n",
       "...                                                      ...   \n",
       "d0b0e459   Global Ocean Circulation Appears To Be Collaps...   \n",
       "af8069e0   Greenland's ice sheet has melted to a point of...   \n",
       "3d1a155a   The Sea Is Rising, but Not Because of Climate ...   \n",
       "8060b507   Climate Change Isnât the End of the World Even...   \n",
       "c3b3947d   Earth heading for 'mini ice age' within 15 yea...   \n",
       "\n",
       "                                                       title our rating  \\\n",
       "public_id                                                                 \n",
       "81a67c96                               - The Washington Post          2   \n",
       "6e5ec6fb                 Rubio Comments on Iran Nuclear Deal          1   \n",
       "d9cd4895   Climate Alarmists Caught Manipulating Temperat...          1   \n",
       "4a1a9b9f   Who are the arsonists setting rural fires in W...          1   \n",
       "6d16fa40   Diabetes prescriptions now cost NHS Â£1bn, figu...          1   \n",
       "...                                                      ...        ...   \n",
       "d0b0e459   Global Ocean Circulation Appears To Be Collaps...          0   \n",
       "af8069e0   Greenland's ice sheet has melted to a point of...          2   \n",
       "3d1a155a   The Sea Is Rising, but Not Because of Climate ...          2   \n",
       "8060b507           Climate Change Isnât the End of the World          2   \n",
       "c3b3947d    Earth heading for 'mini ice age' within 15 years          2   \n",
       "\n",
       "               true     false  partially false     other  final_prediction  \n",
       "public_id                                                                   \n",
       "81a67c96   0.000967  0.000610         0.997826  0.000598                 2  \n",
       "6e5ec6fb   0.000259  0.998082         0.000260  0.001399                 1  \n",
       "d9cd4895   0.000319  0.996054         0.000708  0.002919                 1  \n",
       "4a1a9b9f   0.000348  0.993891         0.001137  0.004624                 1  \n",
       "6d16fa40   0.120679  0.075827         0.740065  0.063430                 2  \n",
       "...             ...       ...              ...       ...               ...  \n",
       "d0b0e459   0.000255  0.997181         0.000324  0.002239                 1  \n",
       "af8069e0   0.024827  0.012409         0.717568  0.245196                 2  \n",
       "3d1a155a   0.003819  0.803527         0.003131  0.189523                 1  \n",
       "8060b507   0.000758  0.954236         0.026244  0.018762                 1  \n",
       "c3b3947d   0.002841  0.909089         0.004739  0.083331                 1  \n",
       "\n",
       "[330 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True = Class 0\n",
    "# False = Class 1\n",
    "# Partially False = Class 3\n",
    "# Other = Class 4\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"predictions.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
