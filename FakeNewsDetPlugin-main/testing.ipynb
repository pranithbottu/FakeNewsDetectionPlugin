{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CheckThat 2022 Baseline\n",
    "\n",
    "*** Author: Mina Schütz ***\n",
    "*** E-Mail: mina.schuetz@h-da.de (1) mina.schuetz@ait.ac.at (2) ***\n",
    "*** Affiliation: Darmstadt University for Applied Sciences (1) and Austrian Institute of Technology GmbH (2) ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "# from transformers import *\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    '''\n",
    "        Params:\n",
    "        --file_path (Str) = Path to TSV/CSV file\n",
    "        Retunrs:\n",
    "        --df (DataFrame) = dataframe with containing the testdataset\n",
    "    '''\n",
    "\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\", encoding=\"utf-8\", index_col=[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    '''\n",
    "        This function changes the classes into numerical values and deletes all NullValues found in the text content\n",
    "        Params:\n",
    "         --df (DataFrame) = DataFrame containing the testset\n",
    "        Returns:\n",
    "        --df (DataFrame) = Cleaned DataFrame, prepared for preprocessing\n",
    "    \n",
    "    '''\n",
    "\n",
    "    df[\"our rating\"] = np.where(df[\"our rating\"] == \"partially false\", 2, df[\"our rating\"])\n",
    "    df[\"our rating\"] = np.where(df[\"our rating\"] == \"false\", 1, df[\"our rating\"])\n",
    "    df[\"our rating\"] = np.where(df[\"our rating\"] == \"true\", 0, df[\"our rating\"])\n",
    "    df[\"our rating\"] = np.where(df[\"our rating\"] == \"other\", 3, df[\"our rating\"])\n",
    "    df['text'].replace('', np.nan, inplace=True)\n",
    "    df['title'].replace('', np.nan, inplace=True)\n",
    "    df.dropna(subset=['title'], inplace=True)\n",
    "    df.dropna(subset=['text'], inplace=True)\n",
    "    df.dropna(subset = [\"our rating\"], inplace=True)\n",
    "    df['text'] = df['title'] +' '+ df['text']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "\n",
    "    '''\n",
    "        Params:\n",
    "        -- model_path = Path to local trained model\n",
    "        Returns:\n",
    "        -- model = BERT-model for testing\n",
    "        -- tokenizer = original BERT tokenizer from HuggingFace\n",
    "    \n",
    "    '''\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-cased', lower_case=False)\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        model_path, \n",
    "        num_labels = 4,\n",
    "        output_attentions = False, \n",
    "        output_hidden_states = False, \n",
    "    )\n",
    "\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, tokenizer):\n",
    "\n",
    "    '''\n",
    "        Preparation of a whole dataset for a forward pass through the model.\n",
    "        \n",
    "        Params:\n",
    "        -- df = Cleaned DataFrame\n",
    "        -- tokenizer = BERT Tokenizer\n",
    "        Returns:\n",
    "        -- Torch DataLoader for the Forward Pass\n",
    "    \n",
    "    '''\n",
    "\n",
    "    MAX_LEN = 512\n",
    "    batch_size = 6\n",
    "\n",
    "    test_sentences = df.text.to_list()\n",
    "    test_labels = df[\"our rating\"].to_list()\n",
    "\n",
    "    test_ids = []\n",
    "    \n",
    "    for sent in test_sentences:\n",
    "        encoded_sent = tokenizer.encode(sent, add_special_tokens = True)\n",
    "        test_ids.append(encoded_sent)\n",
    "\n",
    "    test_ids = pad_sequences(test_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
    "                          value=0, truncating=\"post\", padding=\"post\")\n",
    "    \n",
    "    test_masks = []\n",
    "    for sent in test_ids:\n",
    "        att_mask = [int(token_id > 0) for token_id in sent]\n",
    "        test_masks.append(att_mask)\n",
    "\n",
    "    test_inputs = torch.tensor(test_ids)\n",
    "    test_masks = torch.tensor(test_masks)\n",
    "    test_labels = torch.tensor(test_labels)\n",
    "\n",
    "    test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "    test_sampler = SequentialSampler(test_data)\n",
    "    test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
    "\n",
    "    return test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pass(test_dataloader, model, df):\n",
    "\n",
    "    '''\n",
    "        Evaluation of the testset.\n",
    "\n",
    "        Params: \n",
    "        -- test_dataloader = Torch DataLoader\n",
    "        -- model = The loaded model from disk\n",
    "    \n",
    "    '''\n",
    "\n",
    "    print('Prediction started')\n",
    "\n",
    "    # Set device for PyTorch\n",
    "    if torch.cuda.is_available():    \n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    # Push model to device\n",
    "    model.to(device)\n",
    "\n",
    "    # Check if GPU or CPU \n",
    "    if torch.cuda.is_available():    \n",
    "        model.cuda()\n",
    "    else:\n",
    "        print('No GPU available, using the CPU instead.')\n",
    "        model.cpu()\n",
    "    \n",
    "    # Model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Helper variables for eval metrics\n",
    "    test_accuracy, test_fone, test_precision, test_recall, nb_test_steps = 0, 0, 0, 0, 0\n",
    "    labels_arr, softmax_arr, logits_arr, argmax_arr = [], [], [], []\n",
    "\n",
    "    # Go through the batches in the Prediction Dataloader\n",
    "    for batch in test_dataloader:\n",
    "        \n",
    "        #> Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        #> Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            #> Forward pass, calculate logit predictions\n",
    "            outputs = model(b_input_ids,\n",
    "                            token_type_ids=None,\n",
    "                            attention_mask=b_input_mask)\n",
    "\n",
    "        # Detach logit outputs and labels from model\n",
    "        logits = outputs[0]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        logits_arr.append(logits)\n",
    "\n",
    "        # Softmax on logits for final class\n",
    "        logits_soft_eval = tf.nn.softmax(logits)\n",
    "        logits_arg_eval = np.argmax(logits_soft_eval, axis=1)\n",
    "        \n",
    "        # Calculate eval metrics per batch\n",
    "        tmp_test_accuracy = accuracy_score(label_ids, logits_arg_eval)\n",
    "        tmp_test_precision = precision_score(label_ids, logits_arg_eval, average=\"macro\")\n",
    "        tmp_test_recall = recall_score(label_ids, logits_arg_eval, average=\"macro\")\n",
    "        tmp_test_fone = f1_score(label_ids, logits_arg_eval, average=\"macro\")\n",
    "    \n",
    "        # Add the metrics to a global variable to calculate the actual outcome after the testing\n",
    "        test_accuracy += tmp_test_accuracy\n",
    "        test_precision += tmp_test_precision\n",
    "        test_recall += tmp_test_recall\n",
    "        test_fone += tmp_test_fone\n",
    "    \n",
    "        nb_test_steps += 1   \n",
    "        \n",
    "        # Divide the total metric with the testing steps to get the result\n",
    "        # Accuracy, Precision, Recall, and F1\n",
    "        \n",
    "    for line in logits_arr:\n",
    "        logits_soft_tmp = tf.nn.softmax(line)\n",
    "        logits_arg_tmp = np.argmax(logits_soft_tmp, axis=1)\n",
    "        softmax_arr.append(logits_soft_tmp)\n",
    "        argmax_arr.append(logits_arg_tmp)\n",
    "    \n",
    "    argmax_arr = list(chain.from_iterable(argmax_arr)) \n",
    "    \n",
    "    new_list = []\n",
    "    pred_0, pred_1, pred_2, pred_3 = [], [], [], []\n",
    "    \n",
    "    for line in softmax_arr:\n",
    "        b = line.numpy()\n",
    "        new_list.append(b)\n",
    "\n",
    "    for line in new_list:\n",
    "        for item in line:\n",
    "            pred_0.append(item[0])\n",
    "            pred_1.append(item[1])\n",
    "            pred_2.append(item[2])\n",
    "            pred_3.append(item[3])\n",
    "\n",
    "    df[\"true\"] = pred_0\n",
    "    df[\"false\"] = pred_1\n",
    "    df[\"partially false\"] = pred_2\n",
    "    df[\"other\"] = pred_3\n",
    "    df[\"final_prediction\"] = argmax_arr\n",
    "    \n",
    "    print(\" \")\n",
    "    print(\"------------------------------------------------------------------------------\")\n",
    "    print(\"------------------------------------------------------------------------------\")\n",
    "    print(\"------------------------------------------------------------------------------\")\n",
    "    print(\" \")\n",
    "    print(\"  Accuracy: {0:.2f}\".format(test_accuracy/nb_test_steps))\n",
    "    print(\" \")\n",
    "    print(\"  Precision: {0:.2f}\".format(test_precision/nb_test_steps))\n",
    "    print(\" \")\n",
    "    print(\"  Recall: {0:.2f}\".format(test_recall/nb_test_steps))\n",
    "    print(\" \")\n",
    "    print(\"  F1: {0:.2f}\".format(test_fone/nb_test_steps))\n",
    "    print(\" \")\n",
    "    print('  Testing complete.')\n",
    "    print(\" \")\n",
    "    print(\"------------------------------------------------------------------------------\")\n",
    "    print(\"------------------------------------------------------------------------------\")\n",
    "    print(\"------------------------------------------------------------------------------\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"Task3a_testing.tsv\"\n",
    "model_path = \"model_save_3/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████████████████████████████████████████████████████████████| 208k/208k [00:00<00:00, 2.94MB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████| 29.0/29.0 [00:00<00:00, 14.8kB/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████████| 570/570 [00:00<00:00, 190kB/s]\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction started\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.cuda.IntTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-54fe7a61781d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Test model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-a419ab5f244a>\u001b[0m in \u001b[0;36meval_pass\u001b[1;34m(test_dataloader, model, df)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[1;31m#> Forward pass, calculate logit predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             outputs = model(b_input_ids,\n\u001b[0m\u001b[0;32m     50\u001b[0m                             \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                             attention_mask=b_input_mask)\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1543\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1544\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1545\u001b[1;33m         outputs = self.bert(\n\u001b[0m\u001b[0;32m   1546\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1547\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 989\u001b[1;33m         embedding_output = self.embeddings(\n\u001b[0m\u001b[0;32m    990\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m             \u001b[0minputs_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         return F.embedding(\n\u001b[0m\u001b[0;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   1850\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1852\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.cuda.IntTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "df = load_data(file_path)\n",
    "df = prepare_data(df)\n",
    "model, tokenizer = load_model(model_path)\n",
    "test_dataloader = preprocess_data(df, tokenizer)\n",
    "\n",
    "# Test model\n",
    "df = eval_pass(test_dataloader, model, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>our rating</th>\n",
       "      <th>true</th>\n",
       "      <th>false</th>\n",
       "      <th>partially false</th>\n",
       "      <th>other</th>\n",
       "      <th>final_prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81a67c96</th>\n",
       "      <td>- The Washington Post Former state House Major...</td>\n",
       "      <td>- The Washington Post</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.997826</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6e5ec6fb</th>\n",
       "      <td>Rubio Comments on Iran Nuclear Deal Editor’s n...</td>\n",
       "      <td>Rubio Comments on Iran Nuclear Deal</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.998082</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d9cd4895</th>\n",
       "      <td>Climate Alarmists Caught Manipulating Temperat...</td>\n",
       "      <td>Climate Alarmists Caught Manipulating Temperat...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.996054</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.002919</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4a1a9b9f</th>\n",
       "      <td>Who are the arsonists setting rural fires in W...</td>\n",
       "      <td>Who are the arsonists setting rural fires in W...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.993891</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6d16fa40</th>\n",
       "      <td>Diabetes prescriptions now cost NHS £1bn, figu...</td>\n",
       "      <td>Diabetes prescriptions now cost NHS £1bn, figu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.120679</td>\n",
       "      <td>0.075827</td>\n",
       "      <td>0.740065</td>\n",
       "      <td>0.063430</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d0b0e459</th>\n",
       "      <td>Global Ocean Circulation Appears To Be Collaps...</td>\n",
       "      <td>Global Ocean Circulation Appears To Be Collaps...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.997181</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>af8069e0</th>\n",
       "      <td>Greenland's ice sheet has melted to a point of...</td>\n",
       "      <td>Greenland's ice sheet has melted to a point of...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.024827</td>\n",
       "      <td>0.012409</td>\n",
       "      <td>0.717568</td>\n",
       "      <td>0.245196</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3d1a155a</th>\n",
       "      <td>The Sea Is Rising, but Not Because of Climate ...</td>\n",
       "      <td>The Sea Is Rising, but Not Because of Climate ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003819</td>\n",
       "      <td>0.803527</td>\n",
       "      <td>0.003131</td>\n",
       "      <td>0.189523</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8060b507</th>\n",
       "      <td>Climate Change Isn’t the End of the World Even...</td>\n",
       "      <td>Climate Change Isn’t the End of the World</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.954236</td>\n",
       "      <td>0.026244</td>\n",
       "      <td>0.018762</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c3b3947d</th>\n",
       "      <td>Earth heading for 'mini ice age' within 15 yea...</td>\n",
       "      <td>Earth heading for 'mini ice age' within 15 years</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002841</td>\n",
       "      <td>0.909089</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.083331</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>330 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        text  \\\n",
       "public_id                                                      \n",
       "81a67c96   - The Washington Post Former state House Major...   \n",
       "6e5ec6fb   Rubio Comments on Iran Nuclear Deal Editor’s n...   \n",
       "d9cd4895   Climate Alarmists Caught Manipulating Temperat...   \n",
       "4a1a9b9f   Who are the arsonists setting rural fires in W...   \n",
       "6d16fa40   Diabetes prescriptions now cost NHS £1bn, figu...   \n",
       "...                                                      ...   \n",
       "d0b0e459   Global Ocean Circulation Appears To Be Collaps...   \n",
       "af8069e0   Greenland's ice sheet has melted to a point of...   \n",
       "3d1a155a   The Sea Is Rising, but Not Because of Climate ...   \n",
       "8060b507   Climate Change Isn’t the End of the World Even...   \n",
       "c3b3947d   Earth heading for 'mini ice age' within 15 yea...   \n",
       "\n",
       "                                                       title our rating  \\\n",
       "public_id                                                                 \n",
       "81a67c96                               - The Washington Post          2   \n",
       "6e5ec6fb                 Rubio Comments on Iran Nuclear Deal          1   \n",
       "d9cd4895   Climate Alarmists Caught Manipulating Temperat...          1   \n",
       "4a1a9b9f   Who are the arsonists setting rural fires in W...          1   \n",
       "6d16fa40   Diabetes prescriptions now cost NHS £1bn, figu...          1   \n",
       "...                                                      ...        ...   \n",
       "d0b0e459   Global Ocean Circulation Appears To Be Collaps...          0   \n",
       "af8069e0   Greenland's ice sheet has melted to a point of...          2   \n",
       "3d1a155a   The Sea Is Rising, but Not Because of Climate ...          2   \n",
       "8060b507           Climate Change Isn’t the End of the World          2   \n",
       "c3b3947d    Earth heading for 'mini ice age' within 15 years          2   \n",
       "\n",
       "               true     false  partially false     other  final_prediction  \n",
       "public_id                                                                   \n",
       "81a67c96   0.000967  0.000610         0.997826  0.000598                 2  \n",
       "6e5ec6fb   0.000259  0.998082         0.000260  0.001399                 1  \n",
       "d9cd4895   0.000319  0.996054         0.000708  0.002919                 1  \n",
       "4a1a9b9f   0.000348  0.993891         0.001137  0.004624                 1  \n",
       "6d16fa40   0.120679  0.075827         0.740065  0.063430                 2  \n",
       "...             ...       ...              ...       ...               ...  \n",
       "d0b0e459   0.000255  0.997181         0.000324  0.002239                 1  \n",
       "af8069e0   0.024827  0.012409         0.717568  0.245196                 2  \n",
       "3d1a155a   0.003819  0.803527         0.003131  0.189523                 1  \n",
       "8060b507   0.000758  0.954236         0.026244  0.018762                 1  \n",
       "c3b3947d   0.002841  0.909089         0.004739  0.083331                 1  \n",
       "\n",
       "[330 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True = Class 0\n",
    "# False = Class 1\n",
    "# Partially False = Class 3\n",
    "# Other = Class 4\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"predictions.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
